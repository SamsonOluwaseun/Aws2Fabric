{"cells":[{"cell_type":"markdown","source":["# ðŸ“˜ Incremental JSON File Loader with Metadata Tracking in Microsoft Fabric"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7a14170e-ad00-42d7-ad11-617ab6726b85"},{"cell_type":"markdown","source":["## ðŸ“¥ 1. Silver Layer Data Injection, increamental Loading and Cleaning\n","\n","This is how we import json file and load incrementally using shortcuts"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"28ed4682-ade7-41f8-b5f7-53c23bd38e59"},{"cell_type":"markdown","source":["### âœ… Step 1: Import Required Libraries and Initialise Spark"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e6b4acd-3292-4af7-ada9-d93d50ef37ba"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import input_file_name, regexp_extract, col,monotonically_increasing_id, col, lit, udf\n","from pyspark.sql import Row\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","import requests\n","import json\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"IncrementalJSONLoader\").getOrCreate()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:23.2432955Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:23.2444573Z","execution_finish_time":"2025-06-22T06:46:23.5083583Z","parent_msg_id":"c8d4d55a-c992-4b2c-b23d-a38c46133e17"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cae8d91e-2d28-46de-bea2-b0f956df0704"},{"cell_type":"markdown","source":["### âœ… Step 2: Define File Paths and Metadata Store"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"290334e0-d928-442a-ba65-94690ddb9a3d"},{"cell_type":"code","source":["# Folder where JSON files are stored (OneLake path)\n","data_folder = \"Files/daily_transactions\"\n","\n","# Location to track processed files (as Delta table)\n","metadata_table_path = \"Files/metadata/processed_files\"\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:23.3683398Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:23.5104875Z","execution_finish_time":"2025-06-22T06:46:23.7616691Z","parent_msg_id":"e1322e59-965b-45ef-9e41-e1652199b58a"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"adad479d-29d6-42da-bc12-c0feefbfa4b7"},{"cell_type":"markdown","source":["### âœ… Step 3: Load Metadata of Already Processed Files via Spark"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f0a4b47-80e8-457d-8225-4bea2c5a1736"},{"cell_type":"code","source":["# Try loading existing metadata\n","try:\n","    processed_df = spark.read.format(\"delta\").load(metadata_table_path)\n","    processed_files = set([row[\"file_name\"] for row in processed_df.select(\"file_name\").collect()])\n","except Exception as e:\n","    print(\"No metadata found yet. Starting fresh.\")\n","    processed_files = set()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:23.5310811Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:23.7638071Z","execution_finish_time":"2025-06-22T06:46:24.5783388Z","parent_msg_id":"a1953eea-8e69-48ce-b549-c7c6a3bb276e"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["No metadata found yet. Starting fresh.\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bf138632-8bb2-4fa2-979b-dc5e34e9300c"},{"cell_type":"markdown","source":["### âœ… Step 4: List All JSON Files and Detect New Ones"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"efa978bc-267f-487a-947b-001bd5b96e12"},{"cell_type":"code","source":["# Use Spark to list files (works in Fabric)\n","file_list_df = spark.read.format(\"binaryFile\").load(f\"{data_folder}/*.json\")\n","\n","# Extract file names from full paths\n","file_list_df = file_list_df.withColumn(\"file_name\", regexp_extract(input_file_name(), r\"([^/]+\\.json)$\", 1))\n","\n","# Get distinct filenames\n","all_files = [row[\"file_name\"] for row in file_list_df.select(\"file_name\").distinct().collect()]\n","\n","# Identify new/unprocessed files\n","new_files = sorted([f for f in all_files if f not in processed_files])\n","\n","print(\"New files to load:\", new_files)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:23.9595065Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:24.5803152Z","execution_finish_time":"2025-06-22T06:46:26.874355Z","parent_msg_id":"3c98c6e4-7e1f-4056-9952-a956cfb428ea"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["New files to load: ['2025-06-09.json', '2025-06-10.json', '2025-06-11.json', '2025-06-12.json', '2025-06-13.json']\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cc8edb67-6e1e-4b41-b79b-d3b404ba49a5"},{"cell_type":"markdown","source":["### âœ… Step 5: Load and Append New Files to DataFrame"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4f9a25e2-306d-47a0-a4f6-572c959e7978"},{"cell_type":"code","source":["df_combined = None\n","\n","for filename in new_files:\n","    filepath = f\"{data_folder}/{filename}\"\n","    df = spark.read.option(\"multiline\", \"true\").json(filepath)\n","\n","    if df_combined is None:\n","        df_combined = df\n","    else:\n","        df_combined = df_combined.unionByName(df)\n","\n","    # Mark this file as processed\n","    processed_files.add(filename)\n","\n","# Display combined new data\n","if df_combined:\n","    print(\"All new files to loaded\")\n","else:\n","    print(\"No new files to load.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:24.8029037Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:26.8763972Z","execution_finish_time":"2025-06-22T06:46:30.2634795Z","parent_msg_id":"0683f65f-39bb-42c9-a9a2-5b6d44c7eaf8"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["All new files to loaded\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"af10a54b-090d-40c6-bdba-f0074649835c"},{"cell_type":"markdown","source":["### âœ… Step 6: Update Metadata Table with Processed File Names"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"87aa8ab0-ac08-47d8-a2dc-d15e5082a224"},{"cell_type":"code","source":["# Convert processed file names to DataFrame\n","processed_df_new = spark.createDataFrame([Row(file_name=f) for f in sorted(processed_files)])\n","\n","# Overwrite metadata table\n","processed_df_new.write.mode(\"overwrite\").format(\"delta\").save(metadata_table_path)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:25.4525896Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:30.265623Z","execution_finish_time":"2025-06-22T06:46:34.8561853Z","parent_msg_id":"3c32f0e9-0c0d-4c99-9ce0-a63033bc26a8"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"863965f1-e551-43bb-9025-d9fdd3105fc5"},{"cell_type":"markdown","source":["### âœ… Step 7: Write Combined Data to Delta Table"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f3e34ab7-2f1e-4dc5-a79b-c3691b2be189"},{"cell_type":"code","source":["if df_combined:\n","  output_path = \"Files/processed_output/delta\"\n","  df_combined.write.mode(\"append\").format(\"delta\").save(output_path)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:25.7761326Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:34.8583939Z","execution_finish_time":"2025-06-22T06:46:37.151939Z","parent_msg_id":"63f6c5a7-1b5e-4957-9c65-22073010b480"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1594a7c3-045f-479d-b33f-6615c7573a61"},{"cell_type":"markdown","source":["### âœ… Step 8: (Optional) Preview Metadata"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a95e7b0-3aa3-4b18-9076-cc38da146a85"},{"cell_type":"code","source":["#display(spark.read.format(\"delta\").load(metadata_table_path))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"b1e763fc-840a-49d7-a2c8-eceffadb56f7","normalized_state":"finished","queued_time":"2025-06-22T06:46:25.9950152Z","session_start_time":null,"execution_start_time":"2025-06-22T06:46:37.1539048Z","execution_finish_time":"2025-06-22T06:46:37.4169503Z","parent_msg_id":"63b31c45-473c-42da-8e69-635ef33fb5e4"},"text/plain":"StatementMeta(, b1e763fc-840a-49d7-a2c8-eceffadb56f7, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"c50d57d7-a6c6-488a-9787-e96f54fd7c1c"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"569a9911-f084-4f1b-b30c-bac0809edcdd"}],"default_lakehouse":"569a9911-f084-4f1b-b30c-bac0809edcdd","default_lakehouse_name":"awss3_transformed","default_lakehouse_workspace_id":"6da4d957-9f53-45a0-882a-30684c08cc0d"}}},"nbformat":4,"nbformat_minor":5}